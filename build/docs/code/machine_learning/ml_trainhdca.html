<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of ml_trainhdca</title>
  <meta name="keywords" content="ml_trainhdca">
  <meta name="description" content="Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">machine_learning</a> &gt; ml_trainhdca.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/machine_learning&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>ml_trainhdca

</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function model = ml_trainhdca(varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.
 Model = ml_trainhdca(Trials, Targets, Lambda, Options...)

 HDCA is a 2/3-level hierarchical classifier. The basic idea is that features are partitioned into
 &quot;blocks&quot; of a given size, and a classifier is trained for each block, followed by a classifier
 that acts on the linearly mapped output of the per-block classifiers. Optionally, this can be done
 for a number of given ranges of &quot;channels&quot; in Trials, and then fused with a third-level classifier.

 In:
   Trials       : training data, as in ml_train

   Targets      : target variable, as in ml_train

   Lambda       : within-block regularization parameter, reasonable range: 0:0.1:1, greater is stronger
                  requires that the regularization mode is set to either 'shrinkage' or 'independence' (default: [])
           
   Options  : optional name-value parameters to control the training details:
              'regularization' -&gt; 'shrinkage': covariance shrinkage, depends on plambda 
                                  'independence': feature independence, depends on plambda
                                  'auto': analytical covariance shrinkage, plambda is ignored (default)
              'weight_bias' -&gt; 0/1, take unequal class priors into account for bias calculation
                               default: 0
              'weight_cov' -&gt; 0/1, take unequal class priors into account for covariance calculation
                              default: 0
 Out:
   Model   : a linear model; w is the linear weights, b is the bias; classes indicates the class labels which the model predicts

 Examples:
   % learn a standard shrinkage HDCA model
   model = ml_trainhdca(trials,targets);

   % take unequal class priors into account for both the bias and the covariance matrix
   model = ml_trainhdca(trials,targets,[],'weight_bias',1,'weight_cov',1);

   % use a different type of regularization, which controls feature independence and requires cross-validation
   model = utl_searchmodel({trials,target},'args',{{'lda',search(0:0.1:1),'regularization','independence'}})


 See also:
   <a href="ml_predicthdca.html" class="code" title="function pred = ml_predicthdca(trials, model)">ml_predicthdca</a>

 References:

                           Christian Kothe, Swartz Center for Computational Neuroscience, UCSD
                           2010-04-03</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">

<li><a href="ml_predicthdca.html" class="code" title="function pred = ml_predicthdca(trials, model)">ml_predicthdca</a>	Prediction function for Hierarchical Discriminant Component Analysis</li>
<li><a href="ml_trainhdca.html" class="code" title="function model = ml_trainhdca(varargin)">ml_trainhdca</a>	Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.</li>
<li><a href="ml_trainlda.html" class="code" title="function model = ml_trainlda(varargin)">ml_trainlda</a>	Learn a linear predictive model by (regularized) Linear Discriminant Analysis.</li>
<li><a href="ml_trainvote.html" class="code" title="function model = ml_trainvote(trials, targets, votingscheme, learner, predictor, varargin)">ml_trainvote</a>	Internal meta-algorithm for voting. Used by other machine learning functions.</li>
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">

<li><a href="ml_trainhdca.html" class="code" title="function model = ml_trainhdca(varargin)">ml_trainhdca</a>	Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.</li>
</ul>
<!-- crossreference -->






<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function model = ml_trainhdca(varargin)</a>
0002 <span class="comment">% Learn a linear predictive model by (regularized) Hierarchical Discriminant Component Analysis.</span>
0003 <span class="comment">% Model = ml_trainhdca(Trials, Targets, Lambda, Options...)</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% HDCA is a 2/3-level hierarchical classifier. The basic idea is that features are partitioned into</span>
0006 <span class="comment">% &quot;blocks&quot; of a given size, and a classifier is trained for each block, followed by a classifier</span>
0007 <span class="comment">% that acts on the linearly mapped output of the per-block classifiers. Optionally, this can be done</span>
0008 <span class="comment">% for a number of given ranges of &quot;channels&quot; in Trials, and then fused with a third-level classifier.</span>
0009 <span class="comment">%</span>
0010 <span class="comment">% In:</span>
0011 <span class="comment">%   Trials       : training data, as in ml_train</span>
0012 <span class="comment">%</span>
0013 <span class="comment">%   Targets      : target variable, as in ml_train</span>
0014 <span class="comment">%</span>
0015 <span class="comment">%   Lambda       : within-block regularization parameter, reasonable range: 0:0.1:1, greater is stronger</span>
0016 <span class="comment">%                  requires that the regularization mode is set to either 'shrinkage' or 'independence' (default: [])</span>
0017 <span class="comment">%</span>
0018 <span class="comment">%   Options  : optional name-value parameters to control the training details:</span>
0019 <span class="comment">%              'regularization' -&gt; 'shrinkage': covariance shrinkage, depends on plambda</span>
0020 <span class="comment">%                                  'independence': feature independence, depends on plambda</span>
0021 <span class="comment">%                                  'auto': analytical covariance shrinkage, plambda is ignored (default)</span>
0022 <span class="comment">%              'weight_bias' -&gt; 0/1, take unequal class priors into account for bias calculation</span>
0023 <span class="comment">%                               default: 0</span>
0024 <span class="comment">%              'weight_cov' -&gt; 0/1, take unequal class priors into account for covariance calculation</span>
0025 <span class="comment">%                              default: 0</span>
0026 <span class="comment">% Out:</span>
0027 <span class="comment">%   Model   : a linear model; w is the linear weights, b is the bias; classes indicates the class labels which the model predicts</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% Examples:</span>
0030 <span class="comment">%   % learn a standard shrinkage HDCA model</span>
0031 <span class="comment">%   model = ml_trainhdca(trials,targets);</span>
0032 <span class="comment">%</span>
0033 <span class="comment">%   % take unequal class priors into account for both the bias and the covariance matrix</span>
0034 <span class="comment">%   model = ml_trainhdca(trials,targets,[],'weight_bias',1,'weight_cov',1);</span>
0035 <span class="comment">%</span>
0036 <span class="comment">%   % use a different type of regularization, which controls feature independence and requires cross-validation</span>
0037 <span class="comment">%   model = utl_searchmodel({trials,target},'args',{{'lda',search(0:0.1:1),'regularization','independence'}})</span>
0038 <span class="comment">%</span>
0039 <span class="comment">%</span>
0040 <span class="comment">% See also:</span>
0041 <span class="comment">%   ml_predicthdca</span>
0042 <span class="comment">%</span>
0043 <span class="comment">% References:</span>
0044 <span class="comment">%</span>
0045 <span class="comment">%                           Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0046 <span class="comment">%                           2010-04-03</span>
0047         
0048 args = arg_define([0 2],varargin, <span class="keyword">...</span>
0049     arg_norep(<span class="string">'trials'</span>), <span class="keyword">...</span>
0050     arg_norep(<span class="string">'targets'</span>), <span class="keyword">...</span>
0051     arg({<span class="string">'within_lambda'</span>,<span class="string">'WithinLambda'</span>}, [], [0 1], <span class="string">'Optional regularization parameter. This is for the within-block classifiers. Reasonable range: 0:0.1:1 - greater is stronger. Requires that the regularization mode is set to either &quot;shrinkage&quot; or &quot;independence&quot; (not necessary in &quot;auto&quot; mode).'</span>), <span class="keyword">...</span>
0052     arg({<span class="string">'across_lambda'</span>,<span class="string">'AcrossLambda'</span>}, [], [0 1], <span class="string">'Optional regularization parameter. This is for the across-block classifier. Reasonable range: 0:0.1:1 - greater is stronger. Requires that the regularization mode is set to either &quot;shrinkage&quot; or &quot;independence&quot; (not necessary in &quot;auto&quot; mode).'</span>), <span class="keyword">...</span>
0053     arg({<span class="string">'multimodal_lambda'</span>,<span class="string">'MultimodalLambda'</span>}, [], [0 1], <span class="string">'Optional regularization parameter. This is for the multi-modal classifier. Reasonable range: 0:0.1:1 - greater is stronger. Requires that the regularization mode is set to either &quot;shrinkage&quot; or &quot;independence&quot; (not necessary in &quot;auto&quot; mode).'</span>), <span class="keyword">...</span>
0054     arg({<span class="string">'regularization'</span>,<span class="string">'Regularizer'</span>,<span class="string">'Regularization'</span>}, <span class="string">'auto'</span>, {<span class="string">'none'</span>,<span class="string">'auto'</span>,<span class="string">'shrinkage'</span>,<span class="string">'independence'</span>}, <span class="string">'Type of regularization. Regularizes the robustness / flexibility of covariance estimates. Auto is analytical covariance shrinkage, shrinkage is shrinkage as selected via plambda, and independence is feature independence, also selected via plambda.'</span>), <span class="keyword">...</span>
0055     arg({<span class="string">'modality_ranges'</span>,<span class="string">'ModalityRanges'</span>},{},[],<span class="string">'Channel ranges for each modality. If empty, only one modality is assumed.'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0056     arg({<span class="string">'weight_bias'</span>,<span class="string">'WeightedBias'</span>}, false, [], <span class="string">'Account for class priors in bias. If you do have unequal probabilities for the different classes, this should be enabled.'</span>), <span class="keyword">...</span>
0057     arg({<span class="string">'weight_cov'</span>,<span class="string">'WeightedCov'</span>}, false, [], <span class="string">'Account for class priors in covariance. If you do have unequal probabilities for the different classes, it makes sense to enable this.'</span>), <span class="keyword">...</span>
0058     arg({<span class="string">'votingScheme'</span>,<span class="string">'VotingScheme'</span>},<span class="string">'1vR'</span>,{<span class="string">'1v1'</span>,<span class="string">'1vR'</span>},<span class="string">'Voting scheme. If multi-class classification is used, this determine how binary classifiers are arranged to solve the multi-class problem. 1v1 gets slow for large numbers of classes (as all pairs are tested), but can be more accurate than 1vR.'</span>));
0059 
0060 arg_toworkspace(args);
0061 
0062 <span class="comment">% find the class labels</span>
0063 classes = unique(targets);
0064 <span class="keyword">if</span> length(classes) &gt; 2
0065     <span class="comment">% learn a voting arrangement of models...</span>
0066     model = <a href="ml_trainvote.html" class="code" title="function model = ml_trainvote(trials, targets, votingscheme, learner, predictor, varargin)">ml_trainvote</a>(trials, targets, votingScheme, @<a href="ml_trainhdca.html" class="code" title="function model = ml_trainhdca(varargin)">ml_trainhdca</a>, @<a href="ml_predicthdca.html" class="code" title="function pred = ml_predicthdca(trials, model)">ml_predicthdca</a>, varargin{:},<span class="string">'weight_bias'</span>,true);    <span class="comment">%#ok&lt;*NODEF&gt;</span>
0067 <span class="keyword">elseif</span> length(classes) == 1
0068     error(<span class="string">'BCILAB:only_one_class'</span>,<span class="string">'Your training data set has no trials for one of your classes; you need at least two classes to train a classifier.\n\nThe most likely reasons are that one of your target markers does not occur in the data, or that all your trials of a particular class are concentrated in a single short segment of your data (10 or 20 percent). The latter would be a problem with the experiment design.'</span>);
0069 <span class="keyword">else</span>
0070     <span class="comment">% determine block sizes if necessary</span>
0071     <span class="keyword">if</span> ndims(trials) == 3
0072         <span class="keyword">if</span> isempty(modality_ranges)
0073             modality_ranges = {1:size(trials,1)}; <span class="keyword">end</span>        
0074     <span class="keyword">else</span>
0075         error(<span class="string">'This classifier requires 3d tensor features.'</span>);
0076     <span class="keyword">end</span>
0077             
0078     <span class="comment">% we call vanilla LDA to do the regressions - determine parameters</span>
0079     lda_parameters = hlp_struct2varargin(args,<span class="string">'suppress'</span>,{<span class="string">'trials'</span>,<span class="string">'targets'</span>,<span class="string">'block_sizes'</span>,<span class="string">'within_lambda'</span>,<span class="string">'across_lambda'</span>,<span class="string">'multimodal_lambda'</span>,<span class="string">'modality_ranges'</span>});
0080     
0081     <span class="comment">% for each modality range</span>
0082     <span class="keyword">for</span> m=1:length(modality_ranges)
0083         range = modality_ranges{m};
0084         <span class="comment">% for each block...</span>
0085         <span class="keyword">for</span> b=size(trials,2):-1:1
0086             blocktrials = reshape(trials(range,b,:),[],size(trials,3))';
0087             blockmodels{m}{b} = <a href="ml_trainlda.html" class="code" title="function model = ml_trainlda(varargin)">ml_trainlda</a>(lda_parameters{:},<span class="string">'trials'</span>,blocktrials, <span class="string">'targets'</span>,targets, <span class="string">'lambda'</span>,within_lambda);
0088             blockpredictions{b} = blocktrials*blockmodels{m}{b}.w' - blockmodels{m}{b}.b';
0089         <span class="keyword">end</span>
0090         layertrials = cat(2,blockpredictions{:});
0091         rangemodels{m} = <a href="ml_trainlda.html" class="code" title="function model = ml_trainlda(varargin)">ml_trainlda</a>(lda_parameters{:}, <span class="string">'trials'</span>,layertrials, <span class="string">'targets'</span>,targets, <span class="string">'lambda'</span>,across_lambda); <span class="comment">%#ok&lt;AGROW&gt;</span>
0092         rangepredictions{m} = layertrials*rangemodels{m}.w' - rangemodels{m}.b'; <span class="comment">%#ok&lt;AGROW&gt;</span>
0093     <span class="keyword">end</span>
0094     toptrials = cat(2,rangepredictions{:});
0095     topmodel = <a href="ml_trainlda.html" class="code" title="function model = ml_trainlda(varargin)">ml_trainlda</a>(lda_parameters{:}, <span class="string">'trials'</span>,toptrials, <span class="string">'targets'</span>,targets, <span class="string">'lambda'</span>,multimodal_lambda);
0096     
0097     model = struct(<span class="string">'modality_ranges'</span>,{modality_ranges}, <span class="string">'blockmodels'</span>,{blockmodels}, <span class="string">'rangemodels'</span>,{rangemodels}, <span class="string">'topmodel'</span>,{topmodel});
0098 <span class="keyword">end</span></pre></div>

<hr><address>Generated on Wed 19-Aug-2015 18:06:23 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>